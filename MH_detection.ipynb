{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MH_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9ICp8Z1J8mvT",
        "uLHMOTewBnfq"
      ],
      "authorship_tag": "ABX9TyO8Q19zvpj+xa9aH4Mtn3HJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gail529/MH_streamlit/blob/main/MH_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ICp8Z1J8mvT"
      },
      "source": [
        "# Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfotSi4Jk2YD",
        "outputId": "26310581-ec39-49a8-afe9-f42c07571b8e"
      },
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install afinn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Collecting afinn\n",
            "  Downloading afinn-0.1.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53448 sha256=101b6060f05f685898ecc375f41c177bdd6c621c7f9cfeb92116266d7022f53f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/16/3a/9f0953027434eab5dadf3f33ab3298fa95afa8292fcf7aba75\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eEza3p46dHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebbc8b1-6330-4286-8f95-a358c011d478"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "#tweet preprocessing \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize,TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdmiceGkiXpn",
        "outputId": "3483d8f1-bd5c-4d66-8a8c-4545f411b861"
      },
      "source": [
        "emo_lex=pd.read_excel('/content/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx') # emotion lexicon \n",
        "emolex_df=emo_lex[['English (en)','Positive','Negative','Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']]\n",
        "emotions=emolex_df.columns.drop('English (en)')\n",
        "emolex_df.rename(columns={'English (en)':'word'},inplace=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOzILMYcp4KC"
      },
      "source": [
        "\n",
        "#receive tweet\n",
        "#preprocess it\n",
        "#run it through lexicon\n",
        "#once emotion scores are generated calc dep score\n",
        "#translate emotion score to final value\n",
        "#final value is then translateed to result message\n",
        "#streamlit interface\n",
        "#receive tweet\n",
        "\n",
        "#lowercasing and url,punctuations and numbers removal,\n",
        "def Lowercasing(words):\n",
        "    string=re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\",str(words))\n",
        "    word=string.lower()\n",
        "    return word\n",
        "\n",
        "#Tokenization and (@)handle extraction\n",
        "def Tokenization(tweet):\n",
        "    tokens=sent_tokenize(tweet)\n",
        "    return tokens\n",
        "\n",
        "#punctuations\n",
        "def Punctuation_removal(tokens):\n",
        "    words=[ word for word in tokens if word.isalnum()]\n",
        "    return words\n",
        "\n",
        "#stemming\n",
        "def stemming(text):\n",
        "    stemmer=PorterStemmer()\n",
        "    for  word in text:\n",
        "        stemmed_words=stemmer.stem(word)\n",
        "        return stemmed_words\n",
        "\n",
        "#stopword_removal\n",
        "def remove_stopwords(words):\n",
        "    stop_words=set(stopwords.words(\"english\")) \n",
        "    result=[word for word in words if word not in stop_words ]\n",
        "    return result\n",
        "\n",
        "\n",
        "#lemmatization\n",
        "def lemmatization(text):\n",
        "    lemmatizer=WordNetLemmatizer()\n",
        "    lemmatized_phrase=[]\n",
        "    for word in text:\n",
        "        lemmatized_word=lemmatizer.lemmatize(word)\n",
        "        lemmatized_phrase.append(lemmatized_word)\n",
        "    return lemmatized_phrase\n",
        "\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    tweet_tokens=Tokenization(tweet)\n",
        "    lemmatized_tweet=lemmatization(tweet_tokens)#lemmatization\n",
        "    clean_string=Lowercasing(lemmatized_tweet)#lowercasing and removing numbers\n",
        "    return clean_string\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "LUBp_V1F3t5i",
        "outputId": "f9ea8bed-9dbc-48e8-c8c3-40fededd8415"
      },
      "source": [
        "tweets=pd.read_csv('/content/final_tweets.csv')\n",
        "tweets.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>app_stayaway</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>People can also take advantage of your phone a...</td>\n",
              "      <td>people can also take advantage of your phone a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rykorua</td>\n",
              "      <td>Italia</td>\n",
              "      <td>Christmas is a good time to start practicing g...</td>\n",
              "      <td>christmas is a good time to start practicing g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>allevin18</td>\n",
              "      <td>Minneapolis, MN</td>\n",
              "      <td>\"Driving in the Midst of #Depression\" https://...</td>\n",
              "      <td>driving in the midst of depression   mindwand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>DulleyTopBooks</td>\n",
              "      <td>North Vancouver, B.C. Canada</td>\n",
              "      <td>@BCGovNews May the Prince of Peace give us ALL...</td>\n",
              "      <td>may the prince of peace give u all peace of ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>sadvibes43ver</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Anyone else just pretending they’re ok?\\n#sadt...</td>\n",
              "      <td>anyone else just pretending they  re ok  sadtw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             tweets\n",
              "0           0  ...  people can also take advantage of your phone a...\n",
              "1           1  ...  christmas is a good time to start practicing g...\n",
              "2           2  ...   driving in the midst of depression   mindwand...\n",
              "3           3  ...  may the prince of peace give u all peace of ou...\n",
              "4           4  ...  anyone else just pretending they  re ok  sadtw...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODFicFrk4AZw"
      },
      "source": [
        "tweet=tweets.iloc[1004,5]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZQxbaoySQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df746142-a648-4c43-8263-ff5c201ca6bb"
      },
      "source": [
        "from afinn import Afinn\n",
        "afinn = Afinn(language='en')\n",
        "print(tweet)\n",
        "def tweet_emotions(tweet):\n",
        "    emo_df=pd.DataFrame(0,index=['word'],columns=emotions)\n",
        "    words=word_tokenize(tweet) #the body of text for each individual tweet(row)\n",
        "    for word in words:\n",
        "        emo_score=emolex_df[emolex_df.word == word]   \n",
        "        if emo_score.empty:\n",
        "            continue\n",
        "        else:\n",
        "            for emotion in list(emotions):\n",
        "                emo_df.at['word',emotion] += emo_score[emotion]\n",
        "    \n",
        "    emo_df['afinn_score'] = afinn.score(tweet)\n",
        "    return emo_df\n",
        "\n",
        "\n",
        "emo_df=tweet_emotions(tweet)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rq im gonna pop in here  im diagnosed depression and adhd plus anxiety and add and i take antidepressan  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_hgqedPUXK4",
        "outputId": "7c0f45fb-9b05-44df-d3dc-155bffbb3086"
      },
      "source": [
        "tweet_score=emo_df.iloc[0,:].values\n",
        "\n",
        "weight_list=[1,5,24.28,5.71,15,9.28,0.71,39.28,3.57,2.14,1]\n",
        "weight_list= [float(item) for item in weight_list]\n",
        "final_val = np.dot(tweet_score,weight_list)\n",
        "final_val"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134.4"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECY1uCnGpN9f"
      },
      "source": [
        "\n",
        "def tweet_emotions(tweet):\n",
        "  emo_df=pd.DataFrame(0,index=['word','tweet','sent'],columns=emotions)\n",
        "  tweet=word_tokenize(tweet) #the body of text for each individual tweet(row)\n",
        "  for word in tweet:\n",
        "    emo_score=emolex_df[emolex_df.word == word]   \n",
        "    print(emo_score)  \n",
        "    if not emo_score.empty:\n",
        "        for emotion in list(emotions):\n",
        "            emo_df.at['word',emotion] += emo_score[emotion]\n",
        "  return emo_df\n",
        "\n",
        "def get_emotion_score():\n",
        "    weight_list=[1,5,24.28,5.71,15,9.28,0.71,39.28,3.57,2.14,1,1,5,2.5]\n",
        "    weight_list= [float(item) for item in weight_list]\n",
        "    final_val = np.dot(song,weight_list)\n",
        "    return final_val\n",
        "\n",
        "tweet_emotion_df=tweet_emotion(tweet)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gos86n3sKRtU"
      },
      "source": [
        "final_df=tweet_emotion(tweet_df_1,'tweets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "IAm1Dad5xmlT",
        "outputId": "3691e3eb-3882-440d-ef4e-72b729544a9c"
      },
      "source": [
        "print(emo_score)\n",
        "emo_df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [word, Positive, Negative, Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Anger</th>\n",
              "      <th>Anticipation</th>\n",
              "      <th>Disgust</th>\n",
              "      <th>Fear</th>\n",
              "      <th>Joy</th>\n",
              "      <th>Sadness</th>\n",
              "      <th>Surprise</th>\n",
              "      <th>Trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Positive  Negative  Anger  Anticipation  ...  Joy  Sadness  Surprise  Trust\n",
              "word          0         2      1             0  ...    0        1         0      0\n",
              "tweet         0         0      0             0  ...    0        0         0      0\n",
              "sent          0         0      0             0  ...    0        0         0      0\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN3_z9nfCYxw",
        "outputId": "048637d5-e404-41c7-ca10-414ea808fa36"
      },
      "source": [
        "emo_df.loc['word','Negative']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: Negative, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Soh01ngRqrz9",
        "outputId": "c1fa9cd6-8ec2-439e-9a15-634b5434d3f1"
      },
      "source": [
        "tweet_emotion_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Anger</th>\n",
              "      <th>Anticipation</th>\n",
              "      <th>Disgust</th>\n",
              "      <th>Fear</th>\n",
              "      <th>Joy</th>\n",
              "      <th>Sadness</th>\n",
              "      <th>Surprise</th>\n",
              "      <th>Trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>9698   NaN\n",
              "Name: Positive, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Negative, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Anger, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Anticipation, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Disgust, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Fear, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Joy, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Sadness, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Surprise, dtype: float64</td>\n",
              "      <td>9698   NaN\n",
              "Name: Trust, dtype: float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Positive  ...                                   Trust\n",
              "word   9698   NaN\n",
              "Name: Positive, dtype: float64  ...  9698   NaN\n",
              "Name: Trust, dtype: float64\n",
              "tweet                                        NaN  ...                                     NaN\n",
              "sent                                         NaN  ...                                     NaN\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFb9kWOtuBLS"
      },
      "source": [
        "\n",
        "emolex_df=emo_lex[['English (en)','Positive','Negative','Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']]\n",
        "emotions=emolex_df.columns.drop('English (en)')\n",
        "emolex_df.rename(columns={'English (en)':'word'},inplace=True)\n",
        "\n",
        "def tweet_emotion(tweet):\n",
        "  emo_df=pd.DataFrame(columns=emotions)\n",
        "  #emo_df=pd.DataFrame(0,index=new_tweet_df.index, columns=emotions)\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  \n",
        "  #with tqdm(total=len(list(new_tweet_df.iterrows()))) as pbar:\n",
        "    #for i ,row in new_tweet_df.iterrows(): \n",
        "        #pbar.update(1) #update the progress bar\n",
        "        #tweet=word_tokenize(new_tweet_df.loc[i][col]) #the body of text for each individual tweet(row)\n",
        "        tweet=word_tokenize(tweet) #the body of text for each individual tweet(row)\n",
        "\n",
        "        for word in tweet:\n",
        "            emo_score=emolex_df[emolex_df.word == new]     \n",
        "            if not emo_score.empty:\n",
        "                for emotion in list(emotions):\n",
        "                    emo_df.at[0,emotion] += emo_score[emotion]\n",
        "\n",
        "\"\"\"\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    st.title('A simple streamlit mental health app')\n",
        "    st.write('Want to know if your tweets contain some depressive characteristics')\n",
        "    st.subheader('Key in or paste one of your tweets') \n",
        "    tweet=st.text_area('') \n",
        "    prediction_btn = st.button('predict')\n",
        "    if prediction_btn:\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "normjetwDyxI"
      },
      "source": [
        "# **Preprocessing**"
      ]
    }
  ]
}